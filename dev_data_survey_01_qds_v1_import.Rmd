---
title: "Import and manage Link2Care Survey Data - QDS Visit 1"
date: "2020-12-23 <br> Updated: `r Sys.Date()`"
---

# ‚≠êÔ∏èOverview

This file is used to import the Link2Care follow-up visit survey data and do some initial data cleaning (e.g., create calculated variables). 

**NOTE on using multiple import code files:**
Previously, I was trying to clean all the separate data frames (i.e, QDS v1-v5, REDCap, and Master Log) in a single Rmd file. 

In theory, this is more efficient than importing and cleaning each visit file separately. For example, we can clean "race" instead of cleaning "race_v1", "race_v2", etc.

However, there are at least two issues with that approach:   
1. There are intentional differences in the variable names (e.g., "V1" and "V2"), and unintentional errors (e.g., HEIGHT_3) in the variable names, from data frame to data frame that make combining them very difficult.   
2. These differences and errors can be "fixed"; however, doing so makes the variable names so different from the codebook that the codebook is barely usable.

For now, I'm going to try importing and cleaning each data file using a separate code file. There may be opportunities to make this more efficient in the future.

**NOTE on data sources:**
* The QDS data is exported from QDS in SPSS data format. The data has to be exported by visit (i.e., v1, v2, ... v5). The SPSS data is then added to the UTHealth servers.

* Some of the v3-v5 visits are also done using REDCap. That data is exported from REDCap and added to the UTHealth servers.

**NOTE on Kiteworks:**
Currently, I'm importing all of this data from the UTHealth server. The data should also be available on Kiteworks if you are unable to connect to the server for some reason.


# üì¶Load packages

```{r message=FALSE}
library(dplyr)
library(haven)
library(readr)
library(purrr)
library(tidyr)
library(stringr)
library(officer)
library(testthat)
```

```{r}
source("R/nines_to_na.R")
source("R/spss_to_fs.R")
```


# üåéConnect to UTH server 

```{bash eval=FALSE}
# Don't drill all the way down to live documents because not all of the data is in live documents.
open 'smb://islgpcifs.uthouston.edu/sph_research/Link2Care/'
```


# üì•Import data 

```{r}
v1 <- read_sav("/Volumes/Link2Care/Participant Data/SPSS Data/QDS Data/Visit_1_Data.SAV")
dim(v1) # 264 803
```


# Remove columns of missing data

There are quite a few columns that have missing values for all rows. We
drop those columns below.

```{r}
v1 <- v1 %>% 
  select(
    where(
      ~ !all(is.na(.x))
    )
  )
```

```{r}
ncol(v1) # 795 So, 803 - 795 = 8 columns dropped.
```


# Clean variable names

_See "Notes on cleaning individual L2C data sets for merging" for the rationale, sytle guidelines, and instructions for this section._
  
## Extract content from Word codebook

```{r}
v1_cb_content <- read_docx("docs/codebooks/L2C_V1 Codebook.docx") %>% 
  docx_summary()
```

## Keep the variables of interest only

```{r}
v1_cb_col_names <- v1_cb_content %>%
  filter(style_name%in% c("section_name", "cb_col_name", "col_name")) %>% 
  select(doc_index, style_name:text) %>% 
  pivot_wider(
    names_from = "style_name",
    values_from = "text"
  )
```

## Clean section names

```{r}
v1_cb_col_names <- v1_cb_col_names %>%
  mutate(
    # Remove "Sect-number."
    section_name = str_remove(section_name, "Sect-\\d{1,}."),
    # Remove asterisks
    section_name = str_remove_all(section_name, "\\*"),
    # Remove empty spaces
    section_name = str_trim(section_name),
    # Clean " (SQ_7 - SQ_11)" from exclusion criteria
    section_name = str_remove(section_name, " \\(SQ_7 - SQ_11\\)")
  ) %>% 
  # Fill section down across rows
  fill(section_name)
```

## Record the sections that are at visit 1

We will use this for checking to make sure all of the correct questionnaire sections merged later.

```{r}
q_sections <- list(v1 = unique(v1_cb_col_names$section_name))
# q_sections[["v1"]]
```

```{r}
write_rds(q_sections, "data/questionnaire_section.rds")
```

## Reduce to one row per column

Currently, cb_col_name and col_name are on separate rows. We will spread the different column names vertically across rows so that we can reduce the data frame down to one row per column.

```{r}
v1_cb_col_names <- v1_cb_col_names %>%
  # Spread cb_col_name across rows
  fill(cb_col_name) %>% 
  # Spread col_name across rows within cb_col_name
  group_by(cb_col_name) %>% 
  fill(col_name, .direction = "up") %>% 
  # # For data checking
  # filter(section_name == "Self-Rated Health Questionnaire") %>%
  # ungroup() %>%
  # slice(-1) %>%
  # summarise(
  #   length(unique(cb_col_name)),
  #   length(unique(col_name))
  # )
  group_by(cb_col_name) %>% 
  filter(row_number() == 1) %>% 
  ungroup() %>% 
  # Remove first row
  slice(-1)
```

```{r}
dim(v1_cb_col_names) # 724   4
```

## Standardize new column names

* Remove _V1 and V1 from column names
* Replace spaces with underscores
* Convert to lower case
* Add underscore in-between the abbreviated tool name and question number

```{r}
v1_cb_col_names <- v1_cb_col_names %>%
  mutate(
    # Remove _V1 from column name
    # Remove V1 at end of column name (e.g., DEM1V1)
    # Don't include values for col_name that were changed in the Word
    # document.
    col_name = if_else(
      is.na(col_name),
      str_replace(cb_col_name, "_V1|V1", ""),
      col_name
    ),
    # Replace spaces with underscores
    col_name = str_replace_all(col_name, " ", "_"),
    # Convert to lower case
    col_name = str_to_lower(col_name),
    # Add underscore in-between the abbreviated tool name and question number
    col_name = str_replace(col_name, "([a-z])(\\d)", "\\1_\\2")
  )
```

## Check for duplicate column names

Check to make sure this process didn't accidentally create any duplicate column names

```{r}
test_that("No duplicate col_names were created in the visit 1 data.", {
  check_dup_col_name <- v1_cb_col_names %>% 
    group_by(col_name) %>% 
    filter(max(row_number()) > 1) %>% 
    pull(col_name)
  
  expect_length(check_dup_col_name, 0)
})
```

Save v1_cb_col_names as a key that maps the new names to the old names in case we need that information in the future. Possibly for the codebook.

```{r}
write_csv(v1_cb_col_names, "data/columns.csv")
```

## Replace variable names in the full data frame

Put them in the same order used in the codebook.

**NOTE:** The codebook includes a variable called TEST_V1. This doesn't seem to be in the data.

```{r}
v1_col_order <- v1_cb_col_names %>% 
  # The codebook includes a variable called TEST_V1. This doesn't seem to be in 
  # the data.
  filter(cb_col_name != "TEST_V1") %>% 
  pull(cb_col_name)
```

```{r}
test_section <- v1 %>% 
  select(all_of(v1_col_order))

names(test_section) <- v1_cb_col_names %>% 
  # The codebook includes a variable called TEST_V1. This doesn't seem to be in 
  # the data.
  filter(cb_col_name != "TEST_V1") %>% 
  pull(col_name)

test_section
```




































# üóëClean up

```{r}
rm(nines_to_na, spss_to_fs)
```













